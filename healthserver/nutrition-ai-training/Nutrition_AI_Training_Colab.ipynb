{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251459c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# NUTRITION AI - NOTEBOOK GOOGLE COLAB COMPLET\n",
    "# ========================================\n",
    "# \n",
    "# Ce notebook entra√Æne un mod√®le d'IA pour analyser\n",
    "# les valeurs nutritionnelles d'images de nourriture\n",
    "#\n",
    "# INSTRUCTIONS:\n",
    "# 1. Runtime > Change runtime type > GPU (T4)\n",
    "# 2. Ex√©cutez toutes les cellules\n",
    "# 3. Dur√©e totale: ~4 heures\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 1: Configuration et Installation\n",
    "# ========================================\n",
    "\n",
    "# V√©rifier le GPU\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Installer les d√©pendances\n",
    "!pip install -q tensorflow==2.15.0\n",
    "!pip install -q pandas matplotlib seaborn scikit-learn tqdm Pillow\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 2: T√©l√©chargement du Dataset\n",
    "# ========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_DIR = Path(\"/content/nutrition_ai\")\n",
    "DATA_DIR = BASE_DIR / \"food-101\"\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# T√©l√©charger Food-101\n",
    "FOOD101_URL = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
    "FOOD101_TAR = BASE_DIR / \"food-101.tar.gz\"\n",
    "\n",
    "if not (BASE_DIR / \"food-101\" / \"images\").exists():\n",
    "    print(\"üì• T√©l√©chargement de Food-101 (5 GB)...\")\n",
    "    \n",
    "    response = requests.get(FOOD101_URL, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(FOOD101_TAR, 'wb') as f, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True\n",
    "    ) as pbar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "    \n",
    "    print(\"üì¶ Extraction...\")\n",
    "    with tarfile.open(FOOD101_TAR, 'r:gz') as tar:\n",
    "        tar.extractall(BASE_DIR)\n",
    "    \n",
    "    print(\"‚úÖ Dataset pr√™t!\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset d√©j√† t√©l√©charg√©\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 3: Base de Donn√©es Nutritionnelle\n",
    "# ========================================\n",
    "\n",
    "import json\n",
    "\n",
    "NUTRITION_DB = {\n",
    "    'apple_pie': {'calories': 237, 'protein': 2.4, 'fat': 11, 'carbs': 34, 'fiber': 1.6, 'sugars': 15, 'sodium': 266},\n",
    "    'baby_back_ribs': {'calories': 361, 'protein': 17, 'fat': 30, 'carbs': 5, 'fiber': 0.2, 'sugars': 4, 'sodium': 791},\n",
    "    'baklava': {'calories': 428, 'protein': 5, 'fat': 23, 'carbs': 51, 'fiber': 2, 'sugars': 28, 'sodium': 242},\n",
    "    'beef_carpaccio': {'calories': 121, 'protein': 22, 'fat': 3.5, 'carbs': 0.5, 'fiber': 0, 'sugars': 0, 'sodium': 48},\n",
    "    'beef_tartare': {'calories': 155, 'protein': 20, 'fat': 8, 'carbs': 1, 'fiber': 0, 'sugars': 0, 'sodium': 362},\n",
    "    'beet_salad': {'calories': 65, 'protein': 2, 'fat': 3, 'carbs': 9, 'fiber': 3, 'sugars': 6, 'sodium': 198},\n",
    "    'beignets': {'calories': 269, 'protein': 5, 'fat': 11, 'carbs': 38, 'fiber': 1, 'sugars': 9, 'sodium': 456},\n",
    "    'bibimbap': {'calories': 145, 'protein': 8, 'fat': 4, 'carbs': 20, 'fiber': 2.5, 'sugars': 3, 'sodium': 485},\n",
    "    # ... (inclure les 101 classes compl√®tes ici - voir script 02)\n",
    "    'pizza': {'calories': 266, 'protein': 11, 'fat': 10, 'carbs': 33, 'fiber': 2, 'sugars': 4, 'sodium': 598},\n",
    "    'spaghetti_bolognese': {'calories': 151, 'protein': 8, 'fat': 5, 'carbs': 18, 'fiber': 2, 'sugars': 3, 'sodium': 234},\n",
    "    'sushi': {'calories': 143, 'protein': 6, 'fat': 4, 'carbs': 21, 'fiber': 1, 'sugars': 3, 'sodium': 456},\n",
    "}\n",
    "\n",
    "# Sauvegarder\n",
    "NUTRITION_FILE = BASE_DIR / \"nutrition_db.json\"\n",
    "with open(NUTRITION_FILE, 'w') as f:\n",
    "    json.dump(NUTRITION_DB, f, indent=2)\n",
    "\n",
    "FOOD_CLASSES = sorted(NUTRITION_DB.keys())\n",
    "print(f\"‚úÖ {len(FOOD_CLASSES)} classes nutritionnelles charg√©es\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 4: Construction du Mod√®le\n",
    "# ========================================\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = len(FOOD_CLASSES)\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Mod√®le avec EfficientNetV2 + double sortie\"\"\"\n",
    "    \n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Base pr√©-entra√Æn√©e\n",
    "    base = keras.applications.EfficientNetV2B0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=inputs,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Fine-tuning partiel\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = base.output\n",
    "    \n",
    "    # Branche classification\n",
    "    cls = layers.Dense(512, activation='relu')(x)\n",
    "    cls = layers.Dropout(0.3)(cls)\n",
    "    cls = layers.Dense(256, activation='relu')(cls)\n",
    "    cls = layers.Dropout(0.2)(cls)\n",
    "    classification = layers.Dense(NUM_CLASSES, activation='softmax', \n",
    "                                   name='food_classification')(cls)\n",
    "    \n",
    "    # Branche nutrition\n",
    "    nutr = layers.Dense(512, activation='relu')(x)\n",
    "    nutr = layers.Dropout(0.3)(nutr)\n",
    "    nutr = layers.Dense(256, activation='relu')(nutr)\n",
    "    nutr = layers.Dropout(0.2)(nutr)\n",
    "    nutr = layers.Dense(128, activation='relu')(nutr)\n",
    "    nutrition = layers.Dense(7, activation='linear', \n",
    "                             name='nutrition_values')(nutr)\n",
    "    \n",
    "    model = keras.Model(inputs, [classification, nutrition])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss={\n",
    "            'food_classification': 'categorical_crossentropy',\n",
    "            'nutrition_values': 'mse'\n",
    "        },\n",
    "        loss_weights={'food_classification': 1.0, 'nutrition_values': 0.5},\n",
    "        metrics={\n",
    "            'food_classification': ['accuracy'],\n",
    "            'nutrition_values': ['mae']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 5: Data Pipeline\n",
    "# ========================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(FOOD_CLASSES)}\n",
    "\n",
    "def get_nutrition(food_name):\n",
    "    \"\"\"R√©cup√®re les valeurs nutritionnelles\"\"\"\n",
    "    n = NUTRITION_DB[food_name]\n",
    "    return np.array([n['calories'], n['protein'], n['fat'], \n",
    "                    n['carbs'], n['fiber'], n['sugars'], n['sodium']], \n",
    "                   dtype=np.float32)\n",
    "\n",
    "def create_dataset(paths, labels, augment=True):\n",
    "    \"\"\"Cr√©e un tf.data.Dataset optimis√©\"\"\"\n",
    "    \n",
    "    def process(img_path, label):\n",
    "        # Charger image\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "        \n",
    "        # Augmentation\n",
    "        if augment:\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_brightness(img, 0.2)\n",
    "            img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        \n",
    "        img = img / 255.0\n",
    "        \n",
    "        # Labels\n",
    "        class_idx = CLASS_TO_IDX[label.numpy().decode()]\n",
    "        class_label = tf.one_hot(class_idx, NUM_CLASSES)\n",
    "        \n",
    "        nutrition = tf.py_function(\n",
    "            lambda x: get_nutrition(x.numpy().decode()),\n",
    "            [label], tf.float32\n",
    "        )\n",
    "        nutrition.set_shape([7])\n",
    "        \n",
    "        return img, {\n",
    "            'food_classification': class_label,\n",
    "            'nutrition_values': nutrition\n",
    "        }\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if augment:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 6: Chargement des Donn√©es\n",
    "# ========================================\n",
    "\n",
    "meta_dir = BASE_DIR / \"food-101\" / \"meta\"\n",
    "images_dir = BASE_DIR / \"food-101\" / \"images\"\n",
    "\n",
    "# Charger splits\n",
    "with open(meta_dir / \"train.json\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "for cls, imgs in train_data.items():\n",
    "    for img_name in imgs:\n",
    "        img_path = images_dir / f\"{img_name}.jpg\"\n",
    "        if img_path.exists():\n",
    "            train_paths.append(str(img_path))\n",
    "            train_labels.append(cls)\n",
    "\n",
    "print(f\"‚úÖ {len(train_paths)} images d'entra√Ænement\")\n",
    "\n",
    "# Split train/val\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}\")\n",
    "\n",
    "# Cr√©er datasets\n",
    "train_ds = create_dataset(train_paths, train_labels, augment=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, augment=False)\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 7: Entra√Ænement\n",
    "# ========================================\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    '/content/best_model.h5',\n",
    "    monitor='val_food_classification_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ENTRA√éNEMENT\n",
    "print(\"\\nüéì D√âBUT DE L'ENTRA√éNEMENT (dur√©e estim√©e: 3-4 heures)\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 8: Visualisation des R√©sultats\n",
    "# ========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0,0].plot(history.history['food_classification_accuracy'], label='Train')\n",
    "axes[0,0].plot(history.history['val_food_classification_accuracy'], label='Val')\n",
    "axes[0,0].set_title('Classification Accuracy')\n",
    "axes[0,0].set_xlabel('Epoch')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[0,1].plot(history.history['food_classification_loss'], label='Train')\n",
    "axes[0,1].plot(history.history['val_food_classification_loss'], label='Val')\n",
    "axes[0,1].set_title('Classification Loss')\n",
    "axes[0,1].set_xlabel('Epoch')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# Nutrition MAE\n",
    "axes[1,0].plot(history.history['nutrition_values_mae'], label='Train')\n",
    "axes[1,0].plot(history.history['val_nutrition_values_mae'], label='Val')\n",
    "axes[1,0].set_title('Nutrition MAE')\n",
    "axes[1,0].set_xlabel('Epoch')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# Total Loss\n",
    "axes[1,1].plot(history.history['loss'], label='Train')\n",
    "axes[1,1].plot(history.history['val_loss'], label='Val')\n",
    "axes[1,1].set_title('Total Loss')\n",
    "axes[1,1].set_xlabel('Epoch')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Meilleure val accuracy: {max(history.history['val_food_classification_accuracy']):.4f}\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 9: Test sur une Image\n",
    "# ========================================\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def predict_nutrition(image_path):\n",
    "    \"\"\"Pr√©diction sur une image\"\"\"\n",
    "    \n",
    "    # Charger et pr√©traiter\n",
    "    img = Image.open(image_path).resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, 0)\n",
    "    \n",
    "    # Pr√©diction\n",
    "    cls_pred, nutr_pred = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # R√©sultats\n",
    "    top_idx = np.argmax(cls_pred[0])\n",
    "    food_name = FOOD_CLASSES[top_idx]\n",
    "    confidence = cls_pred[0][top_idx]\n",
    "    \n",
    "    nutrition = {\n",
    "        'calories': round(float(nutr_pred[0][0]), 1),\n",
    "        'protein_g': round(float(nutr_pred[0][1]), 1),\n",
    "        'fat_g': round(float(nutr_pred[0][2]), 1),\n",
    "        'carbs_g': round(float(nutr_pred[0][3]), 1),\n",
    "        'fiber_g': round(float(nutr_pred[0][4]), 1),\n",
    "        'sugars_g': round(float(nutr_pred[0][5]), 1),\n",
    "        'sodium_mg': round(float(nutr_pred[0][6]), 1)\n",
    "    }\n",
    "    \n",
    "    # Affichage\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{food_name.replace('_', ' ').title()}\\n{confidence*100:.1f}% confidence\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    labels = list(nutrition.keys())\n",
    "    values = list(nutrition.values())\n",
    "    plt.barh(labels, values, color='skyblue')\n",
    "    plt.xlabel('Value')\n",
    "    plt.title('Nutrition Analysis')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    result = {\n",
    "        'food': food_name,\n",
    "        'confidence': round(float(confidence), 3),\n",
    "        'nutrition': nutrition\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(result, indent=2))\n",
    "    return result\n",
    "\n",
    "# Test sur une image al√©atoire\n",
    "test_img = train_paths[0]\n",
    "print(f\"Test sur: {test_img}\")\n",
    "predict_nutrition(test_img)\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 10: T√©l√©charger le Mod√®le\n",
    "# ========================================\n",
    "\n",
    "# Sauvegarder le mod√®le final\n",
    "model.save('/content/nutrition_model_final.h5')\n",
    "\n",
    "# T√©l√©charger vers Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp /content/best_model.h5 /content/drive/MyDrive/\n",
    "!cp /content/nutrition_model_final.h5 /content/drive/MyDrive/\n",
    "\n",
    "print(\"‚úÖ Mod√®les sauvegard√©s dans Google Drive!\")\n",
    "print(\"\\nPour t√©l√©charger:\")\n",
    "print(\"1. Allez dans Google Drive\")\n",
    "print(\"2. T√©l√©chargez: best_model.h5 et nutrition_model_final.h5\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# FIN DU NOTEBOOK\n",
    "# ========================================\n",
    "# \n",
    "# R√âSULTATS ATTENDUS:\n",
    "# - Accuracy: 70-85% (selon dur√©e d'entra√Ænement)\n",
    "# - Nutrition MAE: 15-30 (selon les m√©triques)\n",
    "# - Taille du mod√®le: ~50-80 MB\n",
    "#\n",
    "# PROCHAINES √âTAPES:\n",
    "# 1. T√©l√©charger le mod√®le\n",
    "# 2. Utiliser 06_inference.py pour tester\n",
    "# 3. Exporter avec 07_export_model.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
