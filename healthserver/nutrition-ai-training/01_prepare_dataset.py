"""
01_prepare_dataset.py
T√©l√©charge et pr√©pare le dataset Food-101

Utilisation:
    python 01_prepare_dataset.py

Dur√©e estim√©e: 5-10 minutes
"""

import os
import requests
import tarfile
from pathlib import Path
from tqdm import tqdm
import json

# Configuration
BASE_DIR = Path("./nutrition_ai_data")
DATA_DIR = BASE_DIR / "food-101"
DATA_DIR.mkdir(parents=True, exist_ok=True)

FOOD101_URL = "http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz"
FOOD101_TAR = BASE_DIR / "food-101.tar.gz"

def download_file(url, destination):
    """T√©l√©charge un fichier avec barre de progression"""
    print(f"üì• T√©l√©chargement de {url}")
    
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(destination, 'wb') as file, tqdm(
        desc=destination.name,
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as progress_bar:
        for chunk in response.iter_content(chunk_size=8192):
            size = file.write(chunk)
            progress_bar.update(size)
    
    print(f"‚úÖ T√©l√©chargement termin√©: {destination}")

def extract_tar(tar_path, extract_to):
    """Extrait une archive tar.gz"""
    print(f"üì¶ Extraction de {tar_path.name}...")
    
    with tarfile.open(tar_path, 'r:gz') as tar:
        # Obtenir le nombre total de fichiers
        members = tar.getmembers()
        
        with tqdm(total=len(members), desc="Extraction") as progress_bar:
            for member in members:
                tar.extract(member, path=extract_to)
                progress_bar.update(1)
    
    print(f"‚úÖ Extraction termin√©e dans: {extract_to}")

def verify_dataset():
    """V√©rifie que le dataset est complet"""
    images_dir = BASE_DIR / "food-101" / "images"
    meta_dir = BASE_DIR / "food-101" / "meta"
    
    if not images_dir.exists():
        print("‚ùå Dossier images non trouv√©")
        return False
    
    if not meta_dir.exists():
        print("‚ùå Dossier meta non trouv√©")
        return False
    
    # Compter les classes
    classes = [d for d in images_dir.iterdir() if d.is_dir()]
    print(f"üìä {len(classes)} classes trouv√©es")
    
    # Compter les images totales
    total_images = sum(1 for _ in images_dir.rglob("*.jpg"))
    print(f"üñºÔ∏è  {total_images} images trouv√©es")
    
    # V√©rifier les fichiers meta
    train_json = meta_dir / "train.json"
    test_json = meta_dir / "test.json"
    
    if train_json.exists() and test_json.exists():
        with open(train_json) as f:
            train_data = json.load(f)
        with open(test_json) as f:
            test_data = json.load(f)
        
        n_train = sum(len(v) for v in train_data.values())
        n_test = sum(len(v) for v in test_data.values())
        
        print(f"üìà {n_train} images d'entra√Ænement")
        print(f"üìâ {n_test} images de test")
    
    return True

def main():
    print("=" * 60)
    print("üçï PR√âPARATION DU DATASET FOOD-101")
    print("=" * 60)
    print()
    
    # V√©rifier si d√©j√† t√©l√©charg√©
    if (BASE_DIR / "food-101" / "images").exists():
        print("‚ö†Ô∏è  Dataset d√©j√† pr√©sent. V√©rification...")
        if verify_dataset():
            print("‚úÖ Dataset valide. Aucun t√©l√©chargement n√©cessaire.")
            return
    
    # T√©l√©charger
    if not FOOD101_TAR.exists():
        download_file(FOOD101_URL, FOOD101_TAR)
    else:
        print(f"‚ö†Ô∏è  Archive d√©j√† t√©l√©charg√©e: {FOOD101_TAR}")
    
    # Extraire
    extract_tar(FOOD101_TAR, BASE_DIR)
    
    # V√©rifier
    print()
    verify_dataset()
    
    print()
    print("=" * 60)
    print("‚úÖ PR√âPARATION TERMIN√âE")
    print("=" * 60)
    print(f"üìÅ Donn√©es dans: {BASE_DIR}")
    print()
    print("Prochaine √©tape: python 02_create_nutrition_db.py")

if __name__ == "__main__":
    main()